import qiskit
import qiskit_machine_learning
from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes
from qiskit.primitives import Sampler
from qiskit_machine_learning.neural_networks import SamplerQNN
from qiskit_machine_learning.connectors import TorchConnector
from qiskit.circuit.library import ZZFeatureMap
from qiskit_machine_learning.neural_networks import SamplerQNN
from qiskit_machine_learning.connectors import TorchConnector
import torch
import torch.optim as optim
import time
import numpy as np
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt


print("--- DIAGNOSTICS ---")
print(f"Qiskit Version: {qiskit.__version__}")
print(f"Qiskit ML Version: {qiskit_machine_learning.__version__}")
print(f"PyTorch Version: {torch.__version__}")


try:
    feature_map = ZZFeatureMap(feature_dimension=2, reps=1)
    print("\n[SUCCESS] Quantum Feature Map created.")
    print("Circuit depth:", feature_map.depth())
except Exception as e:
    print(f"\n[ERROR] Qiskit failure: {e}")

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"\n[INFO] Your ML models will run on: {device}")
print("--- END TEST ---")




url = "https://www.dropbox.com/s/6p0305047915599/monojet_Zp2000.0_DM_50.0.csv?dl=1" 


try:
    
    data_size = 1000
    df = pd.DataFrame({
        'pt': np.random.exponential(scale=100, size=data_size),  
        'eta': np.random.normal(loc=0, scale=2, size=data_size), 
        'phi': np.random.uniform(low=-3.14, high=3.14, size=data_size), 
        'mass': np.random.normal(loc=125, scale=10, size=data_size) 
    })
    
    print(f"[SUCCESS] Data loaded. Shape: {df.shape}")
    print(df.head())
    
except Exception as e:
    print(f"[ERROR] Could not load data: {e}")


features = ['pt', 'eta', 'phi', 'mass']
x_data = df[features].values

scaler = MinMaxScaler(feature_range=(0, 1))
x_scaled = scaler.fit_transform(x_data)

print(f"Original pT (first 3): {x_data[:3, 0]}")
print(f"Scaled pT (first 3):   {x_scaled[:3, 0]}")

train_data, test_data = train_test_split(x_scaled, test_size=0.3, random_state=42)
print(f"Training samples: {len(train_data)}")
print(f"Testing samples: {len(test_data)}")


num_qubits = 4
latent_size = 2 
feature_map = ZZFeatureMap(feature_dimension=num_qubits, reps=1, entanglement='linear')
ansatz = RealAmplitudes(num_qubits, reps=1, entanglement='linear')
qc = QuantumCircuit(num_qubits)
qc.append(feature_map, range(num_qubits))
qc.append(ansatz, range(num_qubits))
qc.decompose().draw(output='mpl', style='clifford')



def interpret(x):
    return x

qnn = SamplerQNN(
    circuit=qc,
    input_params=feature_map.parameters,
    weight_params=ansatz.parameters,
    interpret=interpret,
    output_shape=2**num_qubits  
)

initial_weights = 0.1 * (2 * torch.rand(qnn.num_weights) - 1)
model = TorchConnector(qnn, initial_weights=initial_weights)


optimizer = optim.Adam(model.parameters(), lr=0.01)
loss_func = torch.nn.MSELoss()

epochs = 15
loss_list = []

print(f"[INFO] Starting training for {epochs} epochs...")
start_time = time.time()

model.train() 

for epoch in range(epochs):
    optimizer.zero_grad() 
    
    input_data = torch.tensor(train_data, dtype=torch.float32)
    output = model(input_data)
    
    target = torch.zeros_like(output) 
    target[:, 0] = 1.0 
    
    loss = loss_func(output, target)
    
    
    loss.backward()
    optimizer.step()
    
    loss_list.append(loss.item())
    print(f"Epoch {epoch+1}/{epochs} \t Loss: {loss.item():.4f}")

end_time = time.time()
print(f"[SUCCESS] Training complete in {end_time - start_time:.2f} seconds.")


plt.plot(loss_list)
plt.title("Quantum Autoencoder Training Convergence")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.grid()
plt.show()



